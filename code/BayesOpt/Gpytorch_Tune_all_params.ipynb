{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6ce4d7-fe31-4ba6-953c-eb539fe0fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#`source /cvmfs/sft.cern.ch/lcg/views/LCG_102/x86_64-centos7-gcc11-opt/setup.sh`\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import yoda2numpy_BayesOpt\n",
    "from yoda2numpy_BayesOpt import Yoda2Numpy\n",
    "\n",
    "import pythia_SBI_utils\n",
    "from pythia_SBI_utils import *\n",
    "\n",
    "FONTSIZE = 14\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : FONTSIZE}\n",
    "mp.rc('font', **font)\n",
    "\n",
    "# set usetex = False if LaTex is not \n",
    "# available on your system or if the \n",
    "# rendering is too slow\n",
    "mp.rc('text', usetex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71549c69-75d3-45c5-aa48-ce6bd9a2388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_DICT = {\n",
    "        'StringZ:aLund' : [0.5, 2.0],\n",
    "        'StringZ:bLund': [0.5, 2.0],\n",
    "        # 'StringZ:rFactC':[0.0, 2.0],\n",
    "        # 'StringZ:rFactB': [0., 2.0],\n",
    "        'StringZ:aExtraSQuark':[0.,2.],\n",
    "        # 'StringZ:aExtraDiquark':[0.,2.],\n",
    "        'StringPT:sigma':[0.,1.],\n",
    "        'StringPT:enhancedFraction':[0.,1.],\n",
    "        # 'StringPT:enhancedWidth':[1.0,4.0],\n",
    "        'StringFlav:ProbStoUD':[0,4.0],\n",
    "        'StringFlav:probQQtoQ':[0,4.0],\n",
    "        'StringFlav:probSQtoQQ':[0,4.0],\n",
    "        # 'StringFlav:ProbQQ1toQQ0':[0,4.0],\n",
    "        'TimeShower:alphaSvalue':[0.06,0.25],\n",
    "        'TimeShower:pTmin':[0.1,2.0]\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "MONASH_DICT = {\n",
    "    \"aLund\" : 0.68, \n",
    "    \"bLund\" : 0.98,\n",
    "    \"rFactC\": 1.32,\n",
    "    \"rFactB\":0.855,\n",
    "    \"aExtraSQuark\": 0.0,\n",
    "    \"aExtraDiquark\":0.97,\n",
    "    \"sigma\":0.335,\n",
    "    \"enhancedFraction\":0.01,\n",
    "    \"enhancedWidth\":2.0,\n",
    "    \"ProbStoUD\":0.217,\n",
    "    \"probQQtoQ\":0.081,\n",
    "    \"probSQtoQQ\":0.915,\n",
    "    \"ProbQQ1toQQ0\": 0.0275,\n",
    "    \"alphaSvalue\": 0.1365,\n",
    "    \"pTmin\": 0.5\n",
    "}\n",
    "\n",
    "REDUCED_MONASH_DICT = {\n",
    "    \"aLund\" : 0.68, \n",
    "    \"bLund\" : 0.98,\n",
    "    \"aExtraSQuark\": 0.0,\n",
    "    \"sigma\":0.335,\n",
    "    \"enhancedFraction\":0.01,\n",
    "    \"ProbStoUD\":0.217,\n",
    "    \"probQQtoQ\":0.081,\n",
    "    \"probSQtoQQ\":0.915,\n",
    "    \"alphaSvalue\": 0.1365,\n",
    "    \"pTmin\": 0.5\n",
    "}\n",
    "\n",
    "\n",
    "def get_param_prefix(param):\n",
    "    for key,val in PARAM_DICT.items():\n",
    "        prefix, postfix = key.split(':')\n",
    "        if postfix == str(param):\n",
    "            return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b8d589-3859-47fa-ad17-6c5ee0710c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample_param:\n",
    "    def __init__(self, param, size):\n",
    "        self.param = param\n",
    "        self.size = size\n",
    "    def uniform(self):\n",
    "        param_prefix = get_param_prefix(self.param)\n",
    "        pre_postfix = param_prefix + ':' + self.param\n",
    "        return torch.tensor(np.random.uniform(\n",
    "                low=PARAM_DICT[pre_postfix][0],\n",
    "                high=PARAM_DICT[pre_postfix][1],\n",
    "                size=self.size))\n",
    "\n",
    "    def linspace(self):\n",
    "        param_prefix = get_param_prefix(self.param)\n",
    "        pre_postfix = param_prefix + ':' + self.param\n",
    "        return torch.linspace(start=PARAM_DICT[pre_postfix][0],\n",
    "                end=PARAM_DICT[pre_postfix][1],\n",
    "                steps=self.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131427c1-5582-42ea-8009-88df3a9df9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pythia_card(aLund, \n",
    "                     bLund,\n",
    "                    aExtraSQuark,\n",
    "                    sigma,\n",
    "                    enhancedFraction,\n",
    "                    ProbStoUD,\n",
    "                    probQQtoQ,\n",
    "                    probSQtoQQ,\n",
    "                    alphaSvalue,\n",
    "                    pTmin\n",
    "                    ):\n",
    "    \n",
    "    cards_dir = os.path.join(os.getcwd(), \"BO_Cards\")\n",
    "    filename = f\"ALEPH_1996_S3486095_BO_card.cmnd\"\n",
    "    file_path = os.path.join(cards_dir, filename)\n",
    "    with open(file_path,'w') as f:\n",
    "        first_block=\"\"\"Main:numberOfEvents = 500          ! number of events to generate\n",
    "Next:numberShowEvent = 0           ! suppress full listing of first events\n",
    "# random seed\n",
    "Random:setSeed = on\n",
    "Random:seed= 0\n",
    "! 2) Beam parameter settings.\n",
    "Beams:idA = 11                ! first beam,  e- = 11\n",
    "Beams:idB = -11                ! second beam, e+ = -11\n",
    "Beams:eCM = 91.2               ! CM energy of collision\n",
    "# Pythia 8 settings for LEP\n",
    "# Hadronic decays including b quarks, with ISR photons switched off\n",
    "WeakSingleBoson:ffbar2gmZ = on\n",
    "23:onMode = off\n",
    "23:onIfAny = 1 2 3 4 5\n",
    "PDF:lepton = off\n",
    "SpaceShower:QEDshowerByL = off\\n\\n\"\"\"\n",
    "        f.write(first_block)\n",
    "        # f.write(f\"Random:seed={indx+1}\")\n",
    "        f.write(f\"StringZ:aLund = {aLund}\\n\\n\")\n",
    "        f.write(f\"StringZ:bLund = {bLund}\\n\\n\")\n",
    "        # f.write(f\"StringZ:rFactC = {float(best_parameters_120['rFactC'])}\\n\\n\")\n",
    "        # f.write(f\"StringZ:rFactB = {float(best_parameters_120['rFactB'])}\\n\\n\")\n",
    "        f.write(f\"StringZ:aExtraSQuark = {aExtraSQuark}\\n\\n\")\n",
    "        # f.write(f\"StringZ:aExtraDiquark = {float(best_parameters_120['aExtraDiquark'])}\\n\\n\")\n",
    "        f.write(f\"StringPT:sigma = {sigma}\\n\\n\")\n",
    "        f.write(f\"StringPT:enhancedFraction = {enhancedFraction}\\n\\n\")\n",
    "        # f.write(f\"StringPT:enhancedWidth = {float(best_parameters_120['enhancedWidth'])}\\n\\n\")\n",
    "        f.write(f\"StringFlav:ProbStoUD = {ProbStoUD}\\n\\n\")\n",
    "        f.write(f\"StringFlav:probQQtoQ = {probQQtoQ}\\n\\n\")\n",
    "        f.write(f\"StringFlav:probSQtoQQ = {probSQtoQQ}\\n\\n\")\n",
    "        # f.write(f\"StringFlav:ProbQQ1toQQ0 = {float(best_parameters_120['ProbQQ1toQQ0'])}\\n\\n\")\n",
    "        f.write(f\"TimeShower:alphaSvalue = {alphaSvalue}\\n\\n\")\n",
    "        f.write(f\"TimeShower:pTmin = {pTmin}\\n\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "def get_pbounds(PARAM_DICT):\n",
    "    pbounds = {}\n",
    "    for key, value in PARAM_DICT.items():\n",
    "        p_name = key.split(':')[1]\n",
    "        p_bound = tuple(value)\n",
    "        pbounds[p_name] = p_bound\n",
    "    return pbounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d3c4b0f-e995-42dc-9740-d859e65d2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_filtered_keys(filtered_data_keys, filtered_mc_keys):\n",
    "    # Initialize empty list for the reduced keys\n",
    "    reduced_data_keys = []\n",
    "    reduced_mc_keys = []\n",
    "    # List of histogram keys that need to be removed\n",
    "    hists_to_remove = ['d35-x01-y01', 'd36-x01-y01', 'd39-x01-y01', 'd40-x01-y01']\n",
    "    \n",
    "    # Iterate over each data key\n",
    "    for data_key in filtered_data_keys:\n",
    "        # Add the key to reduced_data_keys only if it does not match any hist_to_remove\n",
    "        if not any(hist_to_remove in str(data_key) for hist_to_remove in hists_to_remove):\n",
    "            reduced_data_keys.append(data_key)\n",
    "\n",
    "    for mc_key in filtered_mc_keys:\n",
    "        # Add the key to reduced_data_keys only if it does not match any hist_to_remove\n",
    "        if not any(hist_to_remove in str(mc_key) for hist_to_remove in hists_to_remove):\n",
    "            reduced_mc_keys.append(mc_key)\n",
    "            \n",
    "        \n",
    "    return reduced_data_keys, reduced_mc_keys\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "065181a2-29a9-429c-8eec-f953f57cc76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(yoda2numpy_BayesOpt)\n",
    "from yoda2numpy_BayesOpt import Yoda2Numpy\n",
    "importlib.reload(pythia_SBI_utils)\n",
    "from pythia_SBI_utils import *\n",
    "\n",
    "def true_objective_func(aLund, \n",
    "                     bLund,\n",
    "                    aExtraSQuark,\n",
    "                    sigma,\n",
    "                    enhancedFraction,\n",
    "                    ProbStoUD,\n",
    "                    probQQtoQ,\n",
    "                    probSQtoQQ,\n",
    "                    alphaSvalue,\n",
    "                    pTmin\n",
    "                       ):\n",
    "    \n",
    "    # step 1: write .cmnd file \n",
    "    make_pythia_card(aLund, \n",
    "                     bLund,\n",
    "                    aExtraSQuark,\n",
    "                    sigma,\n",
    "                    enhancedFraction,\n",
    "                    ProbStoUD,\n",
    "                    probQQtoQ,\n",
    "                    probSQtoQQ,\n",
    "                    alphaSvalue,\n",
    "                    pTmin\n",
    "                    )\n",
    "    #step 2 run main42 and rivet\n",
    "    os.system(\"\"\"./main42 BO_Cards/ALEPH_1996_S3486095_BO_card.cmnd /media/ali/DATA/TEMP/ALEPH_1996_S3486095_card.fifo\n",
    "    rivet -o ALEPH_1996_S3486095_hist_0.yoda -a ALEPH_1996_S3486095 /media/ali/DATA/TEMP/ALEPH_1996_S3486095_card.fifo\n",
    "\n",
    "    rm /media/ali/DATA/TEMP/ALEPH_1996_S3486095_card.fifo\n",
    "    mv ALEPH_1996_S3486095_hist_0.yoda ALEPH_YODAS_BayesOpt/\"\"\")\n",
    "    \n",
    "\n",
    "    #step 3: get generated yoda file histograms in the form of dataframes\n",
    "    dfdata, dfsims, generated_indices = get_data()\n",
    "    print('DATA DATAFRAME')\n",
    "    print(dfdata['/REF/ALEPH_1996_S3486095/d01-x01-y01'].head())\n",
    "    print('FIRST SIM DATAFRAME')\n",
    "    print(dfsims[generated_indices[0]]['/ALEPH_1996_S3486095/d01-x01-y01'].head())\n",
    "\n",
    "    #step 4: fileter histograms based on our criteria\n",
    "    data_keys, mc_keys = get_hist_names(dfdata)\n",
    "\n",
    "    filtered_data_keys, filtered_mc_keys = filter_keys(dfdata, dfsims, data_keys, mc_keys)\n",
    "\n",
    "    #step 4.5: take out bad histograms\n",
    "    reduced_data_keys, reduced_mc_keys = reduce_filtered_keys(filtered_data_keys, filtered_mc_keys)\n",
    "\n",
    "    \n",
    "    #step 5: get test statistic at each point\n",
    "    X0 = {}\n",
    "    for ii, gen_ind in enumerate(generated_indices):\n",
    "        # X0.append(test_statistic(filtered_data_keys,filtered_mc_keys, dfdata, dfsims[gen_ind], which = 0))\n",
    "        # try:\n",
    "        #     X0.append(test_statistic(filtered_data_keys,filtered_mc_keys, dfdata, dfsims[ii], which = 0))\n",
    "        try:\n",
    "            X0[gen_ind] = test_statistic(reduced_data_keys,\n",
    "                                         reduced_mc_keys, \n",
    "                                         dfdata, \n",
    "                                         dfsims[gen_ind], \n",
    "                                         which = 0)\n",
    "        except Exception:\n",
    "            print('test statistic error in file index: ', gen_ind)\n",
    "            \n",
    "            \n",
    "    objective_func = X0[0]\n",
    "        \n",
    "    os.system(\"rm ALEPH_YODAS_BayesOpt/ALEPH_1996_S3486095_hist_0.yoda\")\n",
    "        \n",
    "    print(f\"objective function = {objective_func}\")\n",
    "    return objective_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c4a2d1-9a98-4c98-845b-0e5ed8b96a50",
   "metadata": {},
   "source": [
    "# Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dce61a9a-ee0a-4c8c-b3b7-71386ce4796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.covar_module = ScaleKernel(RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aaff09-e745-4925-9792-91f1c8f8df2e",
   "metadata": {},
   "source": [
    "## Expected Improvement\n",
    "\n",
    "$$\\operatorname{EI}(x)=\\mathbb{E}\\left[\\max \\left(f_{\\text {best }}-f(x), 0\\right)\\right]$$\n",
    "\n",
    "Assuming $f(x) \\sim \\mathcal{N}\\left(\\mu(x), \\sigma(x)^2\\right)$, the EI can be written as\n",
    "\n",
    "$$\\mathrm{EI}(x)=\\left(\\mu(x)-f_{\\text {best }}-\\xi\\right) \\Phi(Z)+\\sigma(x) \\phi(Z)$$\n",
    "\n",
    "where\n",
    "\n",
    "- $$\\begin{array}{l}\n",
    "Z=\\frac{\\mu(x)-f_{\\text {best }}-\\xi}{\\sigma(x)} \\text { if } \\sigma(x)>0 \\\\\n",
    "Z=0 \\text { if } \\sigma(x)=0\n",
    "\\end{array}$$\n",
    "\n",
    "- $\\Phi$ is the CDF of the standard normal distribution, $\\phi(x)$ is the PDF of the standard normal  distribution\n",
    "\n",
    "- $\\xi$ is a small non-negative number (often set to zero) to introduce a trade-off between exploitation and exploration. **the larger the $\\xi$ the more exploration** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "29ad51fa-c5f6-4c34-bb21-c0563b121814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_improvement(model, observed_y, candidate_set):\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = model(candidate_set)\n",
    "        best_f = observed_y.min()\n",
    "        \n",
    "        mean = observed_pred.mean\n",
    "        sigma = observed_pred.variance.sqrt()\n",
    "        gamma = (best_f - mean) / sigma\n",
    "        ei = sigma * (gamma * torch.distributions.Normal(0, 1).cdf(gamma) + torch.distributions.Normal(0, 1).log_prob(gamma).exp())\n",
    "        return ei\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1707f1ca-126f-4802-bae7-4f92b79f6bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >>> PYTHIA settings will be read from file BO_Cards/ALEPH_1996_S3486095_BO_card.cmnd <<< \n",
      " >>> HepMC events will be written to file /media/ali/DATA/TEMP/ALEPH_1996_S3486095_card.fifo <<< \n",
      "\n",
      "\n",
      " *------------------------------------------------------------------------------------* \n",
      " |                                                                                    | \n",
      " |  *------------------------------------------------------------------------------*  | \n",
      " |  |                                                                              |  | \n",
      " |  |                                                                              |  | \n",
      " |  |   PPP   Y   Y  TTTTT  H   H  III    A      Welcome to the Lund Monte Carlo!  |  | \n",
      " |  |   P  P   Y Y     T    H   H   I    A A     This is PYTHIA version 8.309      |  | \n",
      " |  |   PPP     Y      T    HHHHH   I   AAAAA    Last date of change: 16 Feb 2023  |  | \n",
      " |  |   P       Y      T    H   H   I   A   A                                      |  | \n",
      " |  |   P       Y      T    H   H  III  A   A    Now is 21 Jun 2024 at 20:44:18    |  | \n",
      " |  |                                                                              |  | \n",
      " |  |   Program documentation and an archive of historic versions is found on:     |  | \n",
      " |  |                                                                              |  | \n",
      " |  |                               https://pythia.org/                            |  | \n",
      " |  |                                                                              |  | \n",
      " |  |   PYTHIA is authored by a collaboration consisting of:                       |  | \n",
      " |  |                                                                              |  | \n",
      " |  |   Christian Bierlich, Nishita Desai, Leif Gellersen, Ilkka Helenius, Philip  |  | \n",
      " |  |   Ilten, Leif Lonnblad, Stephen Mrenna, Stefan Prestel, Christian Preuss,    |  | \n",
      " |  |   Torbjorn Sjostrand, Peter Skands, Marius Utheim and Rob Verheyen.          |  | \n",
      " |  |                                                                              |  | \n",
      " |  |   The complete list of authors, including contact information and            |  | \n",
      " |  |   affiliations, can be found on https://pythia.org/.                         |  | \n",
      " |  |   Problems or bugs should be reported on email at authors@pythia.org.        |  | \n",
      " |  |                                                                              |  | \n",
      " |  |   The main program reference is C. Bierlich et al,                           |  | \n",
      " |  |   'A comprehensive guide to the physics and usage of Pythia 8.3',            |  | \n",
      " |  |   SciPost Phys. Codebases 8-r8.3 (2022) [arXiv:2203.11601 [hep-ph]]          |  | \n",
      " |  |                                                                              |  | \n",
      " |  |   PYTHIA is released under the GNU General Public Licence version 2 or later.|  | \n",
      " |  |   Please respect the MCnet Guidelines for Event Generator Authors and Users. |  | \n",
      " |  |                                                                              |  | \n",
      " |  |   Disclaimer: this program comes without any guarantees.                     |  | \n",
      " |  |   Beware of errors and use common sense when interpreting results.           |  | \n",
      " |  |                                                                              |  | \n",
      " |  |   Copyright (C) 2023 Torbjorn Sjostrand                                      |  | \n",
      " |  |                                                                              |  | \n",
      " |  |                                                                              |  | \n",
      " |  *------------------------------------------------------------------------------*  | \n",
      " |                                                                                    | \n",
      " *------------------------------------------------------------------------------------* \n",
      "\n",
      "\n",
      " *-------  PYTHIA Process Initialization  --------------------------*\n",
      " |                                                                  |\n",
      " | We collide e- with e+ at a CM energy of 9.120e+01 GeV            |\n",
      " |                                                                  |\n",
      " |------------------------------------------------------------------|\n",
      " |                                                    |             |\n",
      " | Subprocess                                    Code |   Estimated |\n",
      " |                                                    |    max (mb) |\n",
      " |                                                    |             |\n",
      " |------------------------------------------------------------------|\n",
      " |                                                    |             |\n",
      " | f fbar -> gamma*/Z0                            221 |   4.352e-05 |\n",
      " |                                                                  |\n",
      " *-------  End PYTHIA Process Initialization -----------------------*\n",
      "\n",
      " *-------  PYTHIA Flag + Mode + Parm + Word + FVec + MVec + PVec + WVec Settings (changes only)  ------------------* \n",
      " |                                                                                                                 | \n",
      " | Name                                          |                      Now |      Default         Min         Max | \n",
      " |                                               |                          |                                      | \n",
      " | Beams:eCM                                     |                 91.20000 |    14000.000         0.0             | \n",
      " | Beams:idA                                     |                       11 |         2212                         | \n",
      " | Beams:idB                                     |                      -11 |         2212                         | \n",
      " | Main:numberOfEvents                           |                      500 |         1000           0             | \n",
      " | Next:numberShowEvent                          |                        0 |            1           0             | \n",
      " | PDF:lepton                                    |                      off |           on                         | \n",
      " | Random:seed                                   |                        0 |           -1               900000000 | \n",
      " | Random:setSeed                                |                       on |          off                         | \n",
      " | SpaceShower:QEDshowerByL                      |                      off |           on                         | \n",
      " | WeakSingleBoson:ffbar2gmZ                     |                       on |          off                         | \n",
      " |                                                                                                                 | \n",
      " *-------  End PYTHIA Flag + Mode + Parm + Word + FVec + MVec + PVec + WVec Settings  -----------------------------* \n",
      "\n",
      " --------  PYTHIA Particle Data Table (changed only)  ------------------------------------------------------------------------------\n",
      " \n",
      "      id   name            antiName         spn chg col      m0        mWidth      mMin       mMax       tau0    res dec ext vis wid\n",
      "             no onMode   bRatio   meMode     products \n",
      "\n",
      "      23  Z0                                  3   0   0   91.18760    2.50419   10.00000    0.00000  7.87987e-14   1   1   0   0   0\n",
      "              0     1   0.1540492    0        1       -1 \n",
      "              1     1   0.1194935    0        2       -2 \n",
      "              2     1   0.1540386    0        3       -3 \n",
      "              3     1   0.1193325    0        4       -4 \n",
      "              4     1   0.1523269    0        5       -5 \n",
      "              5     0   0.0335480    0       11      -11 \n",
      "              6     0   0.0667305    0       12      -12 \n",
      "              7     0   0.0335477    0       13      -13 \n",
      "              8     0   0.0667305    0       14      -14 \n",
      "              9     0   0.0334720    0       15      -15 \n",
      "             10     0   0.0667305    0       16      -16 \n",
      "\n",
      " --------  End PYTHIA Particle Data Table  -----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " --------  PYTHIA Info Listing  ---------------------------------------- \n",
      " \n",
      " Beam A: id =     11, pz =  4.560e+01, e =  4.560e+01, m =  5.110e-04.\n",
      " Beam B: id =    -11, pz = -4.560e+01, e =  4.560e+01, m =  5.110e-04.\n",
      "\n",
      " In 1: id =   11, x =  1.000e+00, pdf =  1.000e+00 at Q2 =  8.317e+03.\n",
      " In 2: id =  -11, x =  1.000e+00, pdf =  1.000e+00 at same Q2.\n",
      "\n",
      " Subprocess f fbar -> gamma*/Z0 with code 221 is 2 -> 1.\n",
      " It has sHat =  8.317e+03.\n",
      "     alphaEM =  7.818e-03,  alphaS =  1.300e-01    at Q2 =  8.317e+03.\n",
      "\n",
      " Impact parameter b =  0.000e+00 gives enhancement factor =  1.000e+00.\n",
      " Max pT scale for MPI =  9.120e+01, ISR =  9.120e+01, FSR =  9.120e+01.\n",
      " Number of MPI =     1, ISR =     0, FSRproc =     0, FSRreson =     6.\n",
      "\n",
      " --------  End PYTHIA Info Listing  ------------------------------------\n",
      "\n",
      " --------  PYTHIA Event Listing  (hard process)  -----------------------------------------------------------------------------------\n",
      " \n",
      "    no         id  name            status     mothers   daughters     colours      p_x        p_y        p_z         e          m \n",
      "     0         90  (system)           -11     0     0     0     0     0     0      0.000      0.000      0.000     91.200     91.200\n",
      "     1         11  (e-)               -12     0     0     3     0     0     0      0.000      0.000     45.600     45.600      0.001\n",
      "     2        -11  (e+)               -12     0     0     4     0     0     0      0.000      0.000    -45.600     45.600      0.001\n",
      "     3         11  (e-)               -21     1     0     5     0     0     0      0.000      0.000     45.600     45.600      0.000\n",
      "     4        -11  (e+)               -21     2     0     5     0     0     0      0.000      0.000    -45.600     45.600      0.000\n",
      "     5         23  (Z0)               -22     3     4     6     7     0     0      0.000      0.000      0.000     91.200     91.200\n",
      "     6          3  s                   23     5     0     0     0   101     0     16.629     42.125      5.293     45.600      0.500\n",
      "     7         -3  sbar                23     5     0     0     0     0   101    -16.629    -42.125     -5.293     45.600      0.500\n",
      "                                   Charge sum:  0.000           Momentum sum:      0.000      0.000      0.000     91.200     91.200\n",
      "\n",
      " --------  End PYTHIA Event Listing  -----------------------------------------------------------------------------------------------\n",
      "\n",
      " *-------  PYTHIA Event and Cross Section Statistics  -------------------------------------------------------------*\n",
      " |                                                                                                                 |\n",
      " | Subprocess                                    Code |            Number of events       |      sigma +- delta    |\n",
      " |                                                    |       Tried   Selected   Accepted |     (estimated) (mb)   |\n",
      " |                                                    |                                   |                        |\n",
      " |-----------------------------------------------------------------------------------------------------------------|\n",
      " |                                                    |                                   |                        |\n",
      " | f fbar -> gamma*/Z0                            221 |         518        500        500 |   4.144e-05  0.000e+00 |\n",
      " |                                                    |                                   |                        |\n",
      " | sum                                                |         518        500        500 |   4.144e-05  0.000e+00 |\n",
      " |                                                                                                                 |\n",
      " *-------  End PYTHIA Event and Cross Section Statistics ----------------------------------------------------------*\n",
      "\n",
      " *-------  PYTHIA Error and Warning Messages Statistics  ----------------------------------------------------------* \n",
      " |                                                                                                                 | \n",
      " |  times   message                                                                                                | \n",
      " |                                                                                                                 | \n",
      " |      0   no errors or warnings to report                                                                        | \n",
      " |                                                                                                                 | \n",
      " *-------  End PYTHIA Error and Warning Messages Statistics  ------------------------------------------------------* \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rivet 3.1.9 running on machine 75fc85f49008 (x86_64) at 2024-06-21 20:44:20\n",
      "Reading events from '/media/ali/DATA/TEMP/ALEPH_1996_S3486095_card.fifo'\n",
      "Event 100 (0:00:00 elapsed)\n",
      "Event 200 (0:00:00 elapsed)\n",
      "Event 300 (0:00:00 elapsed)\n",
      "Event 400 (0:00:01 elapsed)\n",
      "Event 500 (0:00:01 elapsed)\n",
      "Finished event loop at 2024-06-21 20:44:21\n",
      "Cross-section = 4.144341e+04 pb\n",
      "Rivet run completed at 2024-06-21 20:44:21, time elapsed = 0:00:01\n",
      "Histograms written to /home/ali/Desktop/Pulled_Github_Repositories/Pythia8_SBI_Tune/code/BayesOpt/ALEPH_1996_S3486095_hist_0.yoda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Rivet.AnalysisHandler: INFO  Using named weights\n",
      "[0, 0]\n",
      "looping over 2 sim yoda files...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 14.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using filename ALEPH_YODAS_BayesOpt/ALEPH_1996_S3486095_hist_0.yoda\n",
      "using filename ALEPH_YODAS_BayesOpt/ALEPH_1996_S3486095_hist_0.yoda\n",
      "\n",
      "using filename ALEPH_YODAS_BayesOpt/data/ALEPH_1996_S3486095.yoda\n",
      "DATA DATAFRAME\n",
      "     xval   xerr-   xerr+       yval     yerr-     yerr+\n",
      "0  0.0025  0.0025  0.0025  12.360000  0.407922  0.407922\n",
      "1  0.0075  0.0025  0.0025  23.330000  0.254951  0.254951\n",
      "2  0.0125  0.0025  0.0025  20.230000  0.156205  0.156205\n",
      "3  0.0175  0.0025  0.0025  16.690001  0.120416  0.120416\n",
      "4  0.0225  0.0025  0.0025  13.410000  0.100000  0.100000\n",
      "FIRST SIM DATAFRAME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xlow  xhigh       sumw  sumw2     sumwx    sumwx2  numEntries\n",
      "0  0.000  0.005  10.800000   4.32  0.035104  0.024955        27.0\n",
      "1  0.005  0.010  26.799999  10.72  0.201656  0.316189        67.0\n",
      "2  0.010  0.015  18.400000   7.36  0.226928  0.567564        46.0\n",
      "3  0.015  0.020  16.799999   6.72  0.290823  1.013259        42.0\n",
      "4  0.020  0.025  13.200000   5.28  0.295014  1.323487        33.0\n",
      " new data keys ['/REF/ALEPH_1996_S3486095/d01-x01-y01', '/REF/ALEPH_1996_S3486095/d02-x01-y01', '/REF/ALEPH_1996_S3486095/d03-x01-y01', '/REF/ALEPH_1996_S3486095/d04-x01-y01', '/REF/ALEPH_1996_S3486095/d05-x01-y01', '/REF/ALEPH_1996_S3486095/d06-x01-y01', '/REF/ALEPH_1996_S3486095/d07-x01-y01', '/REF/ALEPH_1996_S3486095/d08-x01-y01', '/REF/ALEPH_1996_S3486095/d09-x01-y01', '/REF/ALEPH_1996_S3486095/d10-x01-y01', '/REF/ALEPH_1996_S3486095/d11-x01-y01', '/REF/ALEPH_1996_S3486095/d12-x01-y01', '/REF/ALEPH_1996_S3486095/d17-x01-y01', '/REF/ALEPH_1996_S3486095/d18-x01-y01', '/REF/ALEPH_1996_S3486095/d25-x01-y01', '/REF/ALEPH_1996_S3486095/d26-x01-y01', '/REF/ALEPH_1996_S3486095/d27-x01-y01', '/REF/ALEPH_1996_S3486095/d28-x01-y01', '/REF/ALEPH_1996_S3486095/d29-x01-y01', '/REF/ALEPH_1996_S3486095/d30-x01-y01', '/REF/ALEPH_1996_S3486095/d31-x01-y01', '/REF/ALEPH_1996_S3486095/d32-x01-y01', '/REF/ALEPH_1996_S3486095/d33-x01-y01', '/REF/ALEPH_1996_S3486095/d34-x01-y01', '/REF/ALEPH_1996_S3486095/d35-x01-y01', '/REF/ALEPH_1996_S3486095/d36-x01-y01', '/REF/ALEPH_1996_S3486095/d37-x01-y01', '/REF/ALEPH_1996_S3486095/d38-x01-y01', '/REF/ALEPH_1996_S3486095/d39-x01-y01', '/REF/ALEPH_1996_S3486095/d40-x01-y01', '/REF/ALEPH_1996_S3486095/d43-x01-y01']\n",
      " new mc keys ['/ALEPH_1996_S3486095/d01-x01-y01', '/ALEPH_1996_S3486095/d02-x01-y01', '/ALEPH_1996_S3486095/d03-x01-y01', '/ALEPH_1996_S3486095/d04-x01-y01', '/ALEPH_1996_S3486095/d05-x01-y01', '/ALEPH_1996_S3486095/d06-x01-y01', '/ALEPH_1996_S3486095/d07-x01-y01', '/ALEPH_1996_S3486095/d08-x01-y01', '/ALEPH_1996_S3486095/d09-x01-y01', '/ALEPH_1996_S3486095/d10-x01-y01', '/ALEPH_1996_S3486095/d11-x01-y01', '/ALEPH_1996_S3486095/d12-x01-y01', '/ALEPH_1996_S3486095/d17-x01-y01', '/ALEPH_1996_S3486095/d18-x01-y01', '/ALEPH_1996_S3486095/d25-x01-y01', '/ALEPH_1996_S3486095/d26-x01-y01', '/ALEPH_1996_S3486095/d27-x01-y01', '/ALEPH_1996_S3486095/d28-x01-y01', '/ALEPH_1996_S3486095/d29-x01-y01', '/ALEPH_1996_S3486095/d30-x01-y01', '/ALEPH_1996_S3486095/d31-x01-y01', '/ALEPH_1996_S3486095/d32-x01-y01', '/ALEPH_1996_S3486095/d33-x01-y01', '/ALEPH_1996_S3486095/d34-x01-y01', '/ALEPH_1996_S3486095/d35-x01-y01', '/ALEPH_1996_S3486095/d36-x01-y01', '/ALEPH_1996_S3486095/d37-x01-y01', '/ALEPH_1996_S3486095/d38-x01-y01', '/ALEPH_1996_S3486095/d39-x01-y01', '/ALEPH_1996_S3486095/d40-x01-y01', '/ALEPH_1996_S3486095/d43-x01-y01']\n",
      "objective function = 2.416050971321793\n"
     ]
    }
   ],
   "source": [
    "train_x = list(REDUCED_MONASH_DICT.values())\n",
    "train_y=torch.tensor([true_objective_func(*train_x)],dtype=torch.float64)\n",
    "train_x = torch.tensor(train_x,dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2905998a-3015-4800-ad82-2e807978703f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ce417c89-42a6-4134-a49c-7285d92c210b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "151edc96-f138-4245-92fb-25288a04c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample_param:\n",
    "    def __init__(self, param, size):\n",
    "        self.param = param\n",
    "        self.size = size\n",
    "    def uniform(self):\n",
    "        param_prefix = get_param_prefix(self.param)\n",
    "        pre_postfix = param_prefix + ':' + self.param\n",
    "        return torch.tensor(np.random.uniform(\n",
    "                low=PARAM_DICT[pre_postfix][0],\n",
    "                high=PARAM_DICT[pre_postfix][1],\n",
    "                size=self.size))\n",
    "\n",
    "    def linspace(self):\n",
    "        param_prefix = get_param_prefix(self.param)\n",
    "        pre_postfix = param_prefix + ':' + self.param\n",
    "        return torch.linspace(start=PARAM_DICT[pre_postfix][0],\n",
    "                end=PARAM_DICT[pre_postfix][1],\n",
    "                steps=self.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f6ad627d-ec60-47da-ab9c-c6d11316a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "model = GPModel(train_x = train_x, train_y=train_y, likelihood=likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3865d648-1837-439d-9c48-bb74aafea99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_x_candidates(PARAM_DICT, size):\n",
    "    full_matrix = np.empty((size, 10))\n",
    "    \n",
    "    for row in range(size):\n",
    "        result=[]\n",
    "        for key, val in PARAM_DICT.items():\n",
    "            param_name, range_ = key, val\n",
    "            param_postfix = param_name.split(':')[1]\n",
    "            uniform_size_1 = Sample_param(param=param_postfix, size=1).uniform().item()\n",
    "            result.append(uniform_size_1)\n",
    "        full_matrix[row,:] = result\n",
    "        \n",
    "    result = full_matrix\n",
    "    \n",
    "    print(result)\n",
    "    return torch.tensor(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "39482016-dfae-40f8-8103-c10a0ec88b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58020422 0.58537298 1.87701045 0.8460614  0.99791523 2.83186118\n",
      "  0.37583306 3.90679473 0.17772185 1.73063993]\n",
      " [1.41390809 1.01018979 1.52859636 0.59169398 0.98705443 2.78852126\n",
      "  0.1324977  3.64695056 0.17904499 1.1120108 ]]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Flattening the training labels failed. The most common cause of this error is that the shapes of the prior mean and the training labels are mismatched. The shape of the train targets is torch.Size([1]), while the reported shape of the mean is torch.Size([10]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpytorch/models/exact_prediction_strategies.py:47\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.__init__\u001b[0;34m(self, train_inputs, train_prior_dist, train_labels, likelihood, root, inv_root)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[10]' is invalid for input of size 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m likelihood\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), gpytorch\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mfast_pred_var():\n\u001b[0;32m---> 15\u001b[0m     out\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpytorch/models/exact_gp.py:294\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     train_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39mtrain_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# Create the prediction strategy for\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_strategy \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_strategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_prior_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# Concatenate the input to the training input\u001b[39;00m\n\u001b[1;32m    302\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpytorch/models/exact_prediction_strategies.py:37\u001b[0m, in \u001b[0;36mprediction_strategy\u001b[0;34m(train_inputs, train_prior_dist, train_labels, likelihood)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m DefaultPredictionStrategy\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_prior_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpytorch/kernels/scale_kernel.py:124\u001b[0m, in \u001b[0;36mScaleKernel.prediction_strategy\u001b[0;34m(self, train_inputs, train_prior_dist, train_labels, likelihood)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprediction_strategy\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_inputs, train_prior_dist, train_labels, likelihood):\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_prior_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpytorch/kernels/kernel.py:445\u001b[0m, in \u001b[0;36mKernel.prediction_strategy\u001b[0;34m(self, train_inputs, train_prior_dist, train_labels, likelihood)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprediction_strategy\u001b[39m(\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    440\u001b[0m     train_inputs: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m     likelihood: GaussianLikelihood,\n\u001b[1;32m    444\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m exact_prediction_strategies\u001b[38;5;241m.\u001b[39mPredictionStrategy:\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexact_prediction_strategies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDefaultPredictionStrategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_prior_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpytorch/models/exact_prediction_strategies.py:51\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.__init__\u001b[0;34m(self, train_inputs, train_prior_dist, train_labels, likelihood, root, inv_root)\u001b[0m\n\u001b[1;32m     47\u001b[0m     train_labels \u001b[38;5;241m=\u001b[39m train_labels\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;241m*\u001b[39mtrain_labels\u001b[38;5;241m.\u001b[39mshape[: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_shape)], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_shape\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m     49\u001b[0m     )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlattening the training labels failed. The most common cause of this error is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat the shapes of the prior mean and the training labels are mismatched. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shape of the train targets is \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile the reported shape of the mean is \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_prior_dist\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_inputs \u001b[38;5;241m=\u001b[39m train_inputs\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_prior_dist \u001b[38;5;241m=\u001b[39m train_prior_dist\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Flattening the training labels failed. The most common cause of this error is that the shapes of the prior mean and the training labels are mismatched. The shape of the train targets is torch.Size([1]), while the reported shape of the mean is torch.Size([10])."
     ]
    }
   ],
   "source": [
    "candidates = make_x_candidates(PARAM_DICT,2)\n",
    "candidates[0]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "for i in range(2):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = model(train_x)\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        out=model(torch.rand(10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d174be19-7abf-45a4-9f7e-d36191f11bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99199457 1.6838783  1.52013186 0.89603605 0.62453092 1.44938127\n",
      "  3.56925366 3.31861536 0.19156904 0.51661084]\n",
      " [1.42448163 0.75349889 1.92226914 0.06495783 0.76782286 3.5268737\n",
      "  1.14881449 2.93252736 0.16547635 0.74393276]]\n"
     ]
    }
   ],
   "source": [
    "# # Use the Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "# # Optimize the model\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "for i in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_x)\n",
    "    loss = - mll(output, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    x_candidates = make_x_candidates(PARAM_DICT,2)\n",
    "    # ei = expected_improvement(model, train_y, x_candidates)\n",
    "    # ei_argmax = ei.argmax()\n",
    "    # next_x = x_can\n",
    "    \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9920e24a-068f-4855-a556-63d7008cb8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50 - Loss: 2.904\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Flattening the training labels failed. The most common cause of this error is that the shapes of the prior mean and the training labels are mismatched. The shape of the train targets is torch.Size([1]), while the reported shape of the mean is torch.Size([10]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpytorch/models/exact_prediction_strategies.py:47\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.__init__\u001b[0;34m(self, train_inputs, train_prior_dist, train_labels, likelihood, root, inv_root)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[10]' is invalid for input of size 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m         model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     43\u001b[0m         model(torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m---> 45\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[111], line 43\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIter \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m - Loss: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 43\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpytorch/models/exact_gp.py:294\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     train_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39mtrain_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# Create the prediction strategy for\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_strategy \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_strategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_prior_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# Concatenate the input to the training input\u001b[39;00m\n\u001b[1;32m    302\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpytorch/models/exact_prediction_strategies.py:37\u001b[0m, in \u001b[0;36mprediction_strategy\u001b[0;34m(train_inputs, train_prior_dist, train_labels, likelihood)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m DefaultPredictionStrategy\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_prior_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpytorch/kernels/scale_kernel.py:124\u001b[0m, in \u001b[0;36mScaleKernel.prediction_strategy\u001b[0;34m(self, train_inputs, train_prior_dist, train_labels, likelihood)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprediction_strategy\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_inputs, train_prior_dist, train_labels, likelihood):\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_prior_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpytorch/kernels/kernel.py:445\u001b[0m, in \u001b[0;36mKernel.prediction_strategy\u001b[0;34m(self, train_inputs, train_prior_dist, train_labels, likelihood)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprediction_strategy\u001b[39m(\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    440\u001b[0m     train_inputs: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m     likelihood: GaussianLikelihood,\n\u001b[1;32m    444\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m exact_prediction_strategies\u001b[38;5;241m.\u001b[39mPredictionStrategy:\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexact_prediction_strategies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDefaultPredictionStrategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_prior_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpytorch/models/exact_prediction_strategies.py:51\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.__init__\u001b[0;34m(self, train_inputs, train_prior_dist, train_labels, likelihood, root, inv_root)\u001b[0m\n\u001b[1;32m     47\u001b[0m     train_labels \u001b[38;5;241m=\u001b[39m train_labels\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;241m*\u001b[39mtrain_labels\u001b[38;5;241m.\u001b[39mshape[: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_shape)], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_shape\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m     49\u001b[0m     )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlattening the training labels failed. The most common cause of this error is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat the shapes of the prior mean and the training labels are mismatched. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shape of the train targets is \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile the reported shape of the mean is \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_prior_dist\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_inputs \u001b[38;5;241m=\u001b[39m train_inputs\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_prior_dist \u001b[38;5;241m=\u001b[39m train_prior_dist\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Flattening the training labels failed. The most common cause of this error is that the shapes of the prior mean and the training labels are mismatched. The shape of the train targets is torch.Size([1]), while the reported shape of the mean is torch.Size([10])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "# Generate synthetic training data\n",
    "# Simulated data where train_x is 10 individual data points\n",
    "train_x = torch.linspace(0, 1, 10)  # 10 data points along a line\n",
    "train_y = torch.tensor([5.0])  # A single target value for all 10 points (unusual)\n",
    "\n",
    "# This requires special handling in the model because typically train_y would have the same length as train_x\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = GPModel(train_x, train_y, likelihood)\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    for i in range(5):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Iter %d/%d - Loss: %.3f' % (i + 1, 50, loss.item()))\n",
    "        model.eval()\n",
    "        model(torch.rand(10))\n",
    "\n",
    "train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "595a0e39-77ea-469d-808b-d77093b8b483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "22974f2e-ac00-4566-8607-75286d743b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8033ce33-5632-4138-8cd3-59e44a382f50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
